# Tiny config for testing purposes.

NUM_LAYERS = (1, 2)
SHORTEN_FACTORS = (2,)
EMBED_DIM = 128
NUM_HEADS = 4
HEAD_DIM = 32
MLP_DIM = 256
DROPOUT_RATE = 0.1
ATTN_DROPOUT_RATE = 0.1

decoder_stack.TransformerTaskConfig:
  sequence_length = 256
  batch_size = 1

transformer_layer.TransformerLayer:
  use_long_xl_architecture = False

training_loop.Trainer:
  num_steps = 2000
  warmup_steps = 200
  log_every_steps = 100
  test_every_steps = 998
  num_test_steps = 200
  generate_every_steps = 10000
  print_input_every_steps = 100
  checkpoint_every_steps = 100
